
[2025-08-15 16:30:01]
üìú Executing Code:
import pandas as pd
import os
import io

# Define the output directory and create it if it doesn't exist
output_dir = "uploads/2eb715c8-64a0-46a4-ae4b-aa5c15910941"
os.makedirs(output_dir, exist_ok=True)

# Define file paths for the data and metadata
data_path = os.path.join(output_dir, "data.csv")
metadata_path = os.path.join(output_dir, "metadata.txt")

# URL of the Wikipedia page to scrape
url = "https://en.wikipedia.org/wiki/List_of_highest-grossing_films"

# Use pandas to read the HTML tables from the URL
tables = pd.read_html(url)

# The first table on the page is 'Highest-grossing films'
df = tables[0]

# Save the extracted DataFrame to a CSV file
df.to_csv(data_path, index=False)

# Generate the metadata file
with open(metadata_path, "w", encoding="utf-8") as f:
    # Write the path and a short description of the data file
    f.write(f"path: {data_path}\n")
    f.write(
        "description: A table of the highest-grossing films worldwide, scraped from Wikipedia.\n\n"
    )

    # Capture and write the output of df.info()
    buffer = io.StringIO()
    df.info(buf=buffer)
    info_str = buffer.getvalue()
    f.write("df.info():\n")
    f.write(info_str)
    f.write("\n")

    # Write the column names
    f.write("Column names:\n")
    f.write(str(df.columns.tolist()))
    f.write("\n\n")

    # Write the first few rows of the DataFrame
    f.write("First few rows (df.head()):\n")
    f.write(df.head().to_string())
    f.write("\n\n")

    # Write the answer format based on the user's request
    f.write("ANSWER_FORMAT:\n")
    f.write("JSON array of strings")

----------------------------------------

[2025-08-15 16:30:02]
‚úÖ Code executed successfully after installing libraries.
----------------------------------------

[2025-08-15 16:30:50]
üìú Executing Code:
import pandas as pd
import json
import matplotlib

matplotlib.use("Agg")
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64

# Load the dataset
file_path = "uploads/2eb715c8-64a0-46a4-ae4b-aa5c15910941/data.csv"
df = pd.read_csv(file_path)

# --- Data Cleaning ---
# Clean 'Worldwide gross' column, removing '$', 'T', and ',' characters
df["Worldwide gross"] = (
    df["Worldwide gross"].replace({r"[$,T]": ""}, regex=True).astype(float)
)

# Clean 'Peak' column - convert to numeric, coercing errors to NaN
df["Peak"] = pd.to_numeric(df["Peak"], errors="coerce")


# --- Question 1: How many $2 bn movies were released before 2000? ---
movies_2bn_before_2000 = df[
    (df["Worldwide gross"] >= 2_000_000_000) & (df["Year"] < 2000)
]
answer1 = str(len(movies_2bn_before_2000))

# --- Question 2: Which is the earliest film that grossed over $1.5 bn? ---
movies_1_5bn = df[df["Worldwide gross"] >= 1_500_000_000]
earliest_movie_1_5bn = movies_1_5bn.loc[movies_1_5bn["Year"].idxmin()]
answer2 = earliest_movie_1_5bn["Title"]

# --- Question 3: What's the correlation between the Rank and Peak? ---
# Drop rows with NaN in 'Peak' or 'Rank' for correlation calculation
df_corr = df.dropna(subset=["Rank", "Peak"])
correlation = df_corr["Rank"].corr(df_corr["Peak"])
answer3 = f"{correlation:.4f}"

# --- Question 4: Draw a scatterplot of Rank and Peak ---
plt.figure(figsize=(8, 6))
sns.regplot(
    x="Rank",
    y="Peak",
    data=df_corr,
    scatter_kws={"alpha": 0.6},
    line_kws={"color": "red", "linestyle": "--"},
)
plt.title("Rank vs. Peak of Highest-Grossing Films")
plt.xlabel("Rank")
plt.ylabel("Peak")
plt.grid(True)
plt.tight_layout()

# Convert plot to base64
buf = io.BytesIO()
plt.savefig(buf, format="png", dpi=72)
buf.seek(0)
img_b64 = base64.b64encode(buf.read()).decode("utf-8")
answer4 = f"data:image/png;base64,{img_b64}"
plt.close()

# Combine answers into a list of strings as per ANSWER_FORMAT
final_answers = [answer1, answer2, answer3, answer4]

# Save to result.json
output_path = "uploads/2eb715c8-64a0-46a4-ae4b-aa5c15910941/result.json"
with open(output_path, "w") as f:
    json.dump(final_answers, f)

----------------------------------------

[2025-08-15 16:30:50]
‚ùå Error during code execution:
Traceback (most recent call last):
  File "/home/dev/TDS_project2/task_engine.py", line 48, in run_python_code
    execute_code()
  File "/home/dev/TDS_project2/task_engine.py", line 26, in execute_code
    exec(code, exec_globals)
  File "<string>", line 16, in <module>
  File "/home/dev/TDS_project2/venv/lib/python3.12/site-packages/pandas/core/generic.py", line 6662, in astype
    new_data = self._mgr.astype(dtype=dtype, copy=copy, errors=errors)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dev/TDS_project2/venv/lib/python3.12/site-packages/pandas/core/internals/managers.py", line 430, in astype
    return self.apply(
           ^^^^^^^^^^^
  File "/home/dev/TDS_project2/venv/lib/python3.12/site-packages/pandas/core/internals/managers.py", line 363, in apply
    applied = getattr(b, f)(**kwargs)
              ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dev/TDS_project2/venv/lib/python3.12/site-packages/pandas/core/internals/blocks.py", line 784, in astype
    new_values = astype_array_safe(values, dtype, copy=copy, errors=errors)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dev/TDS_project2/venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py", line 237, in astype_array_safe
    new_values = astype_array(values, dtype, copy=copy)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dev/TDS_project2/venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py", line 182, in astype_array
    values = _astype_nansafe(values, dtype, copy=copy)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/dev/TDS_project2/venv/lib/python3.12/site-packages/pandas/core/dtypes/astype.py", line 133, in _astype_nansafe
    return arr.astype(dtype, copy=True)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
ValueError: could not convert string to float: 'SM1922598800'

----------------------------------------

[2025-08-15 16:31:14]
üìú Executing Code:
import pandas as pd
import json
import matplotlib

matplotlib.use("Agg")
import matplotlib.pyplot as plt
import seaborn as sns
import io
import base64

# Load the dataset
file_path = "uploads/2eb715c8-64a0-46a4-ae4b-aa5c15910941/data.csv"
df = pd.read_csv(file_path)

# --- Data Cleaning ---
# Clean 'Worldwide gross' column
# First, remove known non-numeric characters like '$', 'T', and ','
gross_series = df["Worldwide gross"].replace({r"[$,T]": ""}, regex=True)
# Then, convert to numeric, coercing any errors (like 'SM1922598800') into NaN
df["Worldwide gross"] = pd.to_numeric(gross_series, errors="coerce")

# Clean 'Peak' column - convert to numeric, coercing errors to NaN
df["Peak"] = pd.to_numeric(df["Peak"], errors="coerce")


# --- Question 1: How many $2 bn movies were released before 2000? ---
df_q1 = df.dropna(subset=["Worldwide gross", "Year"])
movies_2bn_before_2000 = df_q1[
    (df_q1["Worldwide gross"] >= 2_000_000_000) & (df_q1["Year"] < 2000)
]
answer1 = str(len(movies_2bn_before_2000))

# --- Question 2: Which is the earliest film that grossed over $1.5 bn? ---
df_q2 = df.dropna(subset=["Worldwide gross", "Year", "Title"])
movies_1_5bn = df_q2[df_q2["Worldwide gross"] >= 1_500_000_000]
earliest_movie_1_5bn = movies_1_5bn.loc[movies_1_5bn["Year"].idxmin()]
answer2 = earliest_movie_1_5bn["Title"]

# --- Question 3: What's the correlation between the Rank and Peak? ---
# Drop rows with NaN in 'Peak' or 'Rank' for correlation calculation
df_corr = df.dropna(subset=["Rank", "Peak"])
correlation = df_corr["Rank"].corr(df_corr["Peak"])
answer3 = f"{correlation:.4f}"

# --- Question 4: Draw a scatterplot of Rank and Peak ---
plt.figure(figsize=(8, 6))
sns.regplot(
    x="Rank",
    y="Peak",
    data=df_corr,
    scatter_kws={"alpha": 0.6},
    line_kws={"color": "red", "linestyle": "--"},
)
plt.title("Rank vs. Peak of Highest-Grossing Films")
plt.xlabel("Rank")
plt.ylabel("Peak")
plt.grid(True)
plt.tight_layout()

# Convert plot to base64
buf = io.BytesIO()
plt.savefig(buf, format="png", dpi=72)
buf.seek(0)
img_b64 = base64.b64encode(buf.read()).decode("utf-8")
answer4 = f"data:image/png;base64,{img_b64}"
plt.close()

# Combine answers into a list of strings as per ANSWER_FORMAT
final_answers = [answer1, answer2, answer3, answer4]

# Save to result.json
output_path = "uploads/2eb715c8-64a0-46a4-ae4b-aa5c15910941/result.json"
with open(output_path, "w") as f:
    json.dump(final_answers, f)

----------------------------------------

[2025-08-15 16:31:14]
‚úÖ Code executed successfully after installing libraries.
----------------------------------------
